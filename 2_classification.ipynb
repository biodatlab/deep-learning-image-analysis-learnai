{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Convolutional Neural Networks (CNN)**\n",
    "ใน Notebook นี้เราจะมาลงมือทดลองสร้างและเทรน CNN เบื้องต้นด้วยไลบรารี่ Pytorch, Pytorch Lightning, และ FastAI รวมถึงการทำ Transfer Learning กัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available() # ตรวจสอบว่ามี CUDA หรือ GPU ที่สามารถใช้ได้หรือไม่\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-convolutional-neural-network\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            # dimension of color channels (3 = RGB)\n",
    "            in_channels = 1, \n",
    "            out_channels = 6,\n",
    "            # size of square kernels (use (w,h) for non-square windows)\n",
    "            kernel_size = 5, \n",
    "            stride = 2, # step size\n",
    "            )\n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = 2, # size of square kernel (same as before)\n",
    "            stride = 2,\n",
    "            )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels = 6, # equals to out_channels of the previous conv layer \n",
    "            out_channels = 16,\n",
    "            kernel_size = 5,\n",
    "            ) # use the default stride = 1\n",
    "\n",
    "        ## Linear layers after flatten the convolutional filters\n",
    "        self.fc1 = nn.Linear(\n",
    "            # in_features \n",
    "            # = (previous out_channels) X (kernel_width) X (kernel_height)\n",
    "            in_features = 16 * 5 * 5,\n",
    "            out_features = 120,\n",
    "            )\n",
    "        self.fc2 = nn.Linear(\n",
    "            120, # in_features as a positional argument (no need to specify)\n",
    "            84,\n",
    "            )\n",
    "        # 10 is the number of classes (0-9)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = ConvNet()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DVEGT0chL8V"
   },
   "source": [
    "# **Transfer Learning**\n",
    "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeOZasBexBie"
   },
   "source": [
    "### **Transfer Learning ด้วย Pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_jSrCJrhPHd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "9cd4a35bace64018aff62d79f0bf63c1",
      "ac82fb71af0449cf899e36d650375f17",
      "0de07426548b4b1ca6ac2fdd3ce7bb5c",
      "7eedc7c79a5d4e4eb03b9ac6cc40f55e",
      "e5a121e71b734fd193bf7b62f2201e91",
      "ec7ca718a1024260a5bf0ec10f741adf",
      "f21ff26c2e294c93a4f989794f5dc72a",
      "82dc3b25605148a8bdde583a09e852cb",
      "3d6ce095a98c4dd499a6c03c429acb50",
      "0a5c1f48aa3540049a7f915510c532ae",
      "51c3fbf3ec5e40069725ce4f7e4b0de6"
     ]
    },
    "id": "p_o3vrcGhga3",
    "outputId": "47142c1f-5e7b-494c-d5b3-e1adde054f0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd4a35bace64018aff62d79f0bf63c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class TransferNet(nn.Module):\n",
    "    def __init__(self, backbone, num_classes):\n",
    "        super(TransferNet, self).__init__()\n",
    "        self.model = backbone\n",
    "        # \"freeze\" weights ของ backbone ไม่ให้เปลี่ยนแปลง\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        # เปลี่ยน layer สุดท้ายของโมเดลที่เลือกใช้งาน\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# โหลดโมเดล ResNet18 จาก torchvision.models และส่งเข้า class TransferNet ของเรา\n",
    "backbone = torchvision.models.resnet18(pretrained=True)\n",
    "net = TransferNet(backbone = backbone, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CMMxYKciao_"
   },
   "outputs": [],
   "source": [
    "# กำหนด loop การเทรนโมเดล\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Iterate over the dataloader\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Report loss every 100 batch\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # loss function for classification\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate) # Optimizer\n",
    "scheduler = ReduceLROnPlateau(optimizer, \"min\")\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, net, loss_fn, optimizer)\n",
    "    val_loss = test_loop(val_dataloader, net, loss_fn, optimizer)\n",
    "    scheduler.step(val_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVScMb8e5qXG"
   },
   "source": [
    "### **Transfer Learning ด้วย Pytorch Lightning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kW7j5Y54N38"
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDObj8ML3YJs"
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransferNet(pl.LightningModule): # inherit จาก pl.LightningModule แทน nn.Module\n",
    "    def __init__(self, backbone, num_classes, learning_rate):\n",
    "        super(TransferNet, self).__init__()\n",
    "        self.model = backbone\n",
    "        self.learning_rate = learning_rate\n",
    "        # \"freeze\" weights ของ backbone ไม่ให้เปลี่ยนแปลง\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        # เปลี่ยน layer สุดท้ายของโมเดลที่เลือกใช้งาน\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    # กำหนด loop การเทรนโมเดลภายใน class\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        prediction = self(x)\n",
    "        loss = F.cross_entropy(prediction, y)\n",
    "        return loss\n",
    "\n",
    "    # กำหนดเลือก optimizer ที่นี่เช่นเดียวกัน\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLSC2ND74Vbt"
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=50)\n",
    "backbone = torchvision.models.resnet18(pretrained=True)\n",
    "net = TransferNet(\n",
    "    backbone = backbone,\n",
    "    num_classes = 2,\n",
    "    learning_rate=1e-3) \n",
    "\n",
    "trainer.fit(net, train_dataloaders=train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUZ1i6Ft5XIu"
   },
   "source": [
    "### **Transfer Learning ด้วย FastAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6qfT4Ya5Z2a"
   },
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2021/05/training-state-of-the-art-deep-learning-models-with-fast-ai/\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "\n",
    "# กำหนด folder ที่เก็บข้อมูลไว้ให้กับ ImageDataLoaders\n",
    "# ภายใต้ path ที่กำหนดจะมี 2 folders ย่อย คือ training/ และ validation/ \n",
    "dls = ImageDataLoaders.from_folder(path=path, \n",
    "                                    train='training',\n",
    "                                    valid='validation',\n",
    "                                    valid_pct=0.2,\n",
    "                                    shuffle=True)\n",
    "\n",
    "# กำหนด backbone ที่เราต้องการใช้งานให้กับ cnn_learner เช่น resnet18\n",
    "learner = cnn_learner(dls, \n",
    "                    resnet18, \n",
    "                    metrics=[accuracy, error_rate])\n",
    "\n",
    "learner.fine_tune(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Augmentations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.TrivialAugmentWide(),\n",
    "    T.RandomResizedCrop((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = AnimalDataset(train_filenames, train_labels, transform=train_transform)\n",
    "val_data = AnimalDataset(val_filenames, val_labels, transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDjHIZlekf8J"
   },
   "source": [
    "# **มาทดลองการจำแนกรูปภาพกัน**\n",
    "\n",
    "Taken from [AI builders' repository](https://github.com/ai-builders/curriculum/blob/main/notebooks/04v_classification_pytorch.ipynb)\n",
    "\n",
    "**Authored by**: Titipat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWMpWoXwP-PO"
   },
   "outputs": [],
   "source": [
    "## upload your kaggle.json file to colab workspace first\n",
    "## before running this cell\n",
    "\n",
    "!mkdir /root/.kaggle\n",
    "!cp kaggle.json /root/.kaggle\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUkEPDBPQqi0"
   },
   "outputs": [],
   "source": [
    "# SOURCE: https://www.kaggle.com/competitions/dog-breed-identification/data\n",
    "\n",
    "!kaggle competitions download -c dog-breed-identification\n",
    "!unzip dog-breed-identification.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOW68WLk52Nb"
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPE1UlYk6L5J"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import shutil\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kd067cYu6L5K"
   },
   "outputs": [],
   "source": [
    "# get all image paths\n",
    "img_df = pd.DataFrame(glob(\"data/train/*.jpg\"), columns=[\"path\"])\n",
    "img_df[\"id\"] = img_df.path.map(lambda x: op.basename(x).replace(\".jpg\", \"\"))\n",
    "\n",
    "# read label data\n",
    "label_df = pd.read_csv(\"data/labels.csv\")\n",
    "train_df = img_df.merge(label_df, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "LETRAbRA6L5L",
    "outputId": "3faaace2-c1dc-4825-bfb4-fb221dda6e83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-717db31d-d173-4d1c-8c12-a07904586f6a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train/ec3fd4eea9a6a2c88908c33737442e4a.jpg</td>\n",
       "      <td>ec3fd4eea9a6a2c88908c33737442e4a</td>\n",
       "      <td>kerry_blue_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train/700ef49936ff04f8490ceff02b01127f.jpg</td>\n",
       "      <td>700ef49936ff04f8490ceff02b01127f</td>\n",
       "      <td>leonberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train/c9ea2b424b0074a33ec7a879b1cb25ca.jpg</td>\n",
       "      <td>c9ea2b424b0074a33ec7a879b1cb25ca</td>\n",
       "      <td>rottweiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train/9108f7ab07ed5d12dd618f604867ed75.jpg</td>\n",
       "      <td>9108f7ab07ed5d12dd618f604867ed75</td>\n",
       "      <td>old_english_sheepdog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train/0518691772e78ac6805bf006993665a4.jpg</td>\n",
       "      <td>0518691772e78ac6805bf006993665a4</td>\n",
       "      <td>rhodesian_ridgeback</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-717db31d-d173-4d1c-8c12-a07904586f6a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-717db31d-d173-4d1c-8c12-a07904586f6a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-717db31d-d173-4d1c-8c12-a07904586f6a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              path  \\\n",
       "0  data/train/ec3fd4eea9a6a2c88908c33737442e4a.jpg   \n",
       "1  data/train/700ef49936ff04f8490ceff02b01127f.jpg   \n",
       "2  data/train/c9ea2b424b0074a33ec7a879b1cb25ca.jpg   \n",
       "3  data/train/9108f7ab07ed5d12dd618f604867ed75.jpg   \n",
       "4  data/train/0518691772e78ac6805bf006993665a4.jpg   \n",
       "\n",
       "                                 id                 breed  \n",
       "0  ec3fd4eea9a6a2c88908c33737442e4a    kerry_blue_terrier  \n",
       "1  700ef49936ff04f8490ceff02b01127f              leonberg  \n",
       "2  c9ea2b424b0074a33ec7a879b1cb25ca            rottweiler  \n",
       "3  9108f7ab07ed5d12dd618f604867ed75  old_english_sheepdog  \n",
       "4  0518691772e78ac6805bf006993665a4   rhodesian_ridgeback  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2OW6ePIk6L5L"
   },
   "outputs": [],
   "source": [
    "train_df, validation_df = train_test_split(train_df, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEPFUry56L5L",
    "outputId": "ffd261bb-49b7-4fb6-8fe2-4b3f2e1364f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set = 8177, validation set = 2045\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of training set = {}, validation set = {}\".format(len(train_df), len(validation_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDzvopLj6L5M"
   },
   "outputs": [],
   "source": [
    "root_dir = \"data/dogdata/\"\n",
    "for df, f in zip([train_df, validation_df], [\"train\", \"validation\"]):\n",
    "    for _, r in df.iterrows():\n",
    "        # create subfolder if it doesn't exist\n",
    "        d = op.join(root_dir, f, r.breed)\n",
    "        if not op.exists(d):\n",
    "            os.makedirs(d)\n",
    "        shutil.copy(r.path, op.join(root_dir, f, r.breed, f\"{r.id}.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfwDAW3c6L5R"
   },
   "source": [
    "### **Image classification ด้วย Pytorch Lightning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sl82Yb2p6L5R"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsTeBEG-6L5R"
   },
   "outputs": [],
   "source": [
    "train_transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.TrivialAugmentWide(),\n",
    "    T.RandomResizedCrop((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELA3zUpT6L5R"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(\"data/dogdata/train/\", transform=train_transform)\n",
    "val_data = datasets.ImageFolder(\"data/dogdata/validation/\", transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDEYrrjv6L5R"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D--CH1M56L5R"
   },
   "outputs": [],
   "source": [
    "classes = train_data.classes\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4W4pNnV86L5R"
   },
   "outputs": [],
   "source": [
    "class DogResNet(pl.LightningModule):\n",
    "    def __init__(self, n_classes=120):\n",
    "        super(DogResNet, self).__init__()\n",
    "        \n",
    "        # จำนวนของพันธุ์น้องหมา (120)\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # ใช้สถาปัตยกรรม resnet34; เปลี่ยน layer สุดท้าย\n",
    "        self.backbone = models.resnet34(pretrained=True)\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        # เปลี่ยน fc layer เป็น output ขนาด 120\n",
    "        self.backbone.fc = torch.nn.Linear(self.backbone.fc.in_features, n_classes)\n",
    "        \n",
    "        self.entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        preds = self.backbone(x)\n",
    "        return preds\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = self.entropy_loss(logits, y)\n",
    "        y_pred = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        # log metrics ที่สำคัญไว้เพื่อการวิเคราะห์ในภายหลัง\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", self.accuracy(y_pred, y))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = self.entropy_loss(logits, y)\n",
    "        y_pred = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        # log metrics ที่สำคัญไว้เพื่อการวิเคราะห์ในภายหลัง\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", self.accuracy(y_pred, y))\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160,
     "referenced_widgets": [
      "1a9ad9ac419940cca811f5b800379951",
      "5595b6ad7fc844afb015f3bed026cde4",
      "ee91d4c17b384eb8b2696ca77de6e3f9",
      "8e01aca8215941adb20a3bb5c5ef94eb",
      "b801fac7f8ce43d3983205bd11a95b39",
      "0f5c025d1cc9494ba56feaeb4f4419c6",
      "401f3bf4c9fa4f67a7ddd2d1d0b6c181",
      "48aac8b54ccf48118b132fad5dc6f618",
      "2bb7ea5700a14b97ac2a39639f4d905f",
      "3394f607556f4132a19e6ccf2529e134",
      "54e3ec41cfe941d9bd9709f165adde4a"
     ]
    },
    "id": "DNhox75t6L5S",
    "outputId": "7897d592-6f4f-4c9b-c5d1-1ba73b6dd669"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9ad9ac419940cca811f5b800379951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DogResNet(n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jB9_eBHl6L5S"
   },
   "outputs": [],
   "source": [
    "# callback เพื่อให้ Trainer เซฟโมเดลไว้ในไฟล์ checkpoint เมื่อผลลัพธ์ val_loss ลดต่ำกว่าที่เคย\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"./checkpoints/dogbreed/\",\n",
    "    filename=\"resnet18--{epoch:02d}-{val_acc:.2f}-{val_loss:.2f}\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616,
     "referenced_widgets": [
      "6ef85ce5690e4b8a80eb2238cca2279d",
      "feb42ccc232f41778d76e333f2abc25f",
      "5559fc499c4640f4909ed4eb5808ba12",
      "92b632a7338f4b52a128fd5b27814828",
      "24dba9b8e75347e7a6595aca7e051207",
      "2d0ada5928ae4cd4bd3b49a18f4d9cda",
      "4e9a9b836e244419b28df7c2c1e75dd6",
      "b3ebde3c574c477aa97d48246663d585",
      "015a982867e24a6fb1b2d613ab3e51d7",
      "d17b7d61e718474984e7671dea4a108a",
      "8c1ac2ffb2274d18bbd515cfca8cfc74",
      "afca2bdebe6949dca964012a58bdefc7",
      "f27e9cf8c0f74e888eb060f011f916b8",
      "c3d8adbe49ed4557b1b93ba1df4783d0",
      "b268abc60662486aa3db43783acdcd96",
      "e186bf625db2498ab47cb2b3e8e7c097",
      "d39f89bb90e54598823a279ca6b40198",
      "4eb29472f21e4da7bf08970986214fe9",
      "fc7db8a85daa4b17917e7f1d4f9535d4",
      "529e438c10cc4b3395ed1646e92aafe5",
      "6187c0d3a56a47d9a07578244de6bb96",
      "dd74400a78f74e38aba0c49d4bab6420",
      "04042eca3fe44ad7ac9d813ca77049b2",
      "6e88793ce00c4d4e97a4f70aeded40a6",
      "3ca8b48f6ac746aeb385de7bf2113706",
      "598f96eeda2449b2b5778012ff09c031",
      "7ed8f29e74c14445a03e82c1437f14eb",
      "c4672705c9c44b899e0a9076586af86a",
      "84255454821349028d421c0592138b85",
      "9f02bcb358694b65be4e6764c199146e",
      "70c9a5a3a4df45859dee0c1008ac96d5",
      "1dc4dd7a53f24949ad52e9526df976ad",
      "4a52f9b29adc4fa3821b42298c45b6d8",
      "a7ac2b42598e40cbb92dd2dcb26833e5",
      "ec57a6335a874e05b1655b459f0e0cab",
      "80b1cc7b1bf944b2accfbc81de676bae",
      "74c9a0f55029436d9bd34283d09e52ea",
      "675a7c1046274ea8b8f8961c2319ad4c",
      "762cb753770a4911b0fc8701f5e37d98",
      "bcec093377684f1aae7916ff6c85607b",
      "bdf095d4fee540c2a084d0b332276148",
      "4d434af0fb6245038f69b14c49464bf1",
      "105913e82aa442458de0694e512451b7",
      "521da0858c654f9cb052cda1d27819ac",
      "f99c09dd785541b6b69d6a037cb0ff99",
      "55f9d9a5aae642b99d2b0fd0ab7b73b5",
      "1b0417c1d19a41d28a6c7986b14def6b",
      "822a1f76326d43638d871cfea5099351",
      "dafee7b8c65a4c53b92a02e30ec2becd",
      "8299165b90034000b3b3ae7ef14dd7a5",
      "b5b17a4f06c34bd69b3b8fcd9ecd6bbf",
      "2e033704e2884d57b3c2cedda9f6036c",
      "5e3cc4fe7ddb4299b4b8048658f5c88a",
      "ad7b3ee6681a445bafb243d13e6efb85",
      "7174c253ef7c489cb9c40de15b96565a",
      "c919c2c368bc4451bd6eae110d0b286b",
      "1023d60846a446ccb64392a607c2bdb8",
      "a8764a8ac5eb4f67ba70339e3951f7e3",
      "0f4ee9254d114e88b919fcbb6985a4b2",
      "d82e58f8eed749a89aa76f37e06589ef",
      "87ad51174dee47148cf1dae430e35366",
      "9cbaecc0af1b45dd9315f21e50dfbc80",
      "3b3d43b6505f4f06aaff196ffaf2ede1",
      "c34c99465a014662a754efbbdb878d40",
      "f7d49c88419f4869b85ede21f47c3fdc",
      "02ed42e436d94d8a908826b747d38e98",
      "6b82f62b48704a4a8717efd4affed643",
      "ff044c7c67ac4d5eb06823d0de1ebceb",
      "be51f020caf948b7a1ea0964ad572f54",
      "d85b861923e541ec80486782f16e090e",
      "8e85392f24374c41bf2380dd54c2cf23",
      "2041473eb52e49adbfe95b08241d359d",
      "43e09db6a4a643c2a0330d2295f59387",
      "07a927c844f84103a67a68bd0afd8371",
      "df6da470047f47a0b6d15bf95c142ebd",
      "fc9c1fd2412a4339bb983d503325945c",
      "942ccc10aea24e969148fb14b2649c03",
      "855d8f1717b544088b8d501d0e64a327",
      "f2f0a893e2514e208dc2e68a34bdccc4",
      "f9e6e8fb4f284f019624b5e0c2ae9217",
      "7180216217c64b7691b75b89ac460bc8",
      "2e979c55e5b141d398206f9147192d9a",
      "e0a2753d463f47d1bb90ecb16dda98c6",
      "065aa6a48d93465db1b00477a02b9606",
      "a283163f6d0e42f1a4502cda7dbe714a",
      "5b8a24dd176c49bb841bbbf083a6572d",
      "707438cda25f4c6084a3960492e4a315",
      "e76efc29a84a45db8dae40034836af7c",
      "2a205a4f4cb74eca8b147f1bb63b494a",
      "ec1d76f7705d483c8a7f88395ee72c22",
      "fe9353bcfa7c4ff6ac1dfa71cd6f2e90",
      "eef00af08b344ffa887a4036145c5e6f",
      "2cadeac6267245a982732d73714b8475",
      "f86d43b75a7c4297b6b2dc2c10959796",
      "097b48dff22d43cea28ec2a909c6b4f8",
      "e0d9518daa154206b1348747a3a20a70",
      "069d690dd944461597a23a6e8c2ec545",
      "ee19debd93ee4afdb8d65ac50cb84e10",
      "f6623e587c6e4b64a802b16b7e042602",
      "0cf82c179b5c4895b7d72ad24bb4a3e4",
      "18b93da064c04c319dcf9ec9895309fd",
      "a010c43edcbc489e80e6cd474072e43b",
      "3a8f6729b64e4b29aa8e6da4a572d3d9",
      "36985c8856d64c75b3a45b24ef454e1a",
      "c57e583e8fe44e448d9e92d206e4ab9b",
      "518ce2ec6b0742c48fbf484d5c477695",
      "3456b40ddd0d474291f92822c29ea63c",
      "5fef662579404ff882529a51682b808b",
      "5a3f406a15ce49cdaa093d5564ca0404",
      "436123c59a0b4b91a5bdc9b50692365c",
      "797ecb3ffd5f40b08c24f51864d796d4",
      "787f320aeb534fb3845b6ab2bb2516ed",
      "368a39794c9c44e7ba069a1981281b01",
      "a6324c469d544585a440ee74b5c0e511",
      "a91a44cbb464464f9034eb1388543831",
      "4c528c9f0ea14307b90351c54bde2a17",
      "74465cf5c1844c7aa5244b63b46c1c42",
      "1c21a062618945a89af8e8db9fc3172d",
      "8ff462b2cada4d4fb0591429156c79e0",
      "68a0b7f805794a1199d309b332eff50e",
      "35ac5fc0384a4a54ba72a13565ba4fe2",
      "c3e4be5bfd9b44979a74c78bdfc953c9",
      "082fd398d3de40bc93159a3222d36e46",
      "8c5a222b47394c4784f15847e0670562",
      "2cfee86f33b44575ba700b45308c2e0b",
      "04ebb3de4d15465c9322ea9538503aa0",
      "1333613472014aaba316e0ced52d5c6f",
      "bdf7574be9ec45d1a8725ca8663a7d74",
      "414a1913eac0470c84889fb1df0643f7",
      "d3861119bbc349689b68a64ff31d921f",
      "d483ab98f32344f39738f03d7ed5d2ab",
      "46955b1a2fc14cc3af8d106983ee2625"
     ]
    },
    "id": "D29xYXLN6L5S",
    "outputId": "5cec40b1-5b4c-4df7-c95e-bae1966c20fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:446: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type             | Params\n",
      "--------------------------------------------------\n",
      "0 | backbone     | ResNet           | 21.3 M\n",
      "1 | entropy_loss | CrossEntropyLoss | 0     \n",
      "2 | accuracy     | Accuracy         | 0     \n",
      "--------------------------------------------------\n",
      "61.6 K    Trainable params\n",
      "21.3 M    Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.385    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef85ce5690e4b8a80eb2238cca2279d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afca2bdebe6949dca964012a58bdefc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04042eca3fe44ad7ac9d813ca77049b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 256: 'val_loss' reached 1.47828 (best 1.47828), saving model to '/content/checkpoints/dogbreed/resnet18--epoch=00-val_acc=0.64-val_loss=1.48.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ac2b42598e40cbb92dd2dcb26833e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 512: 'val_loss' reached 0.98061 (best 0.98061), saving model to '/content/checkpoints/dogbreed/resnet18--epoch=01-val_acc=0.74-val_loss=0.98.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99c09dd785541b6b69d6a037cb0ff99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 768: 'val_loss' reached 0.87887 (best 0.87887), saving model to '/content/checkpoints/dogbreed/resnet18--epoch=02-val_acc=0.74-val_loss=0.88.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c919c2c368bc4451bd6eae110d0b286b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 1024: 'val_loss' reached 0.77370 (best 0.77370), saving model to '/content/checkpoints/dogbreed/resnet18--epoch=03-val_acc=0.76-val_loss=0.77.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b82f62b48704a4a8717efd4affed643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 1280: 'val_loss' reached 0.73592 (best 0.73592), saving model to '/content/checkpoints/dogbreed/resnet18--epoch=04-val_acc=0.77-val_loss=0.74.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855d8f1717b544088b8d501d0e64a327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 1536: 'val_loss' reached 0.72709 (best 0.72709), saving model to '/content/checkpoints/dogbreed/resnet18--epoch=05-val_acc=0.78-val_loss=0.73.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a205a4f4cb74eca8b147f1bb63b494a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 1792: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf82c179b5c4895b7d72ad24bb4a3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 2048: 'val_loss' reached 0.70046 (best 0.70046), saving model to '/content/checkpoints/dogbreed/resnet18--epoch=07-val_acc=0.78-val_loss=0.70.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797ecb3ffd5f40b08c24f51864d796d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 2304: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e4be5bfd9b44979a74c78bdfc953c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 2560: 'val_loss' reached 0.70019 (best 0.70019), saving model to '/content/checkpoints/dogbreed/resnet18--epoch=09-val_acc=0.78-val_loss=0.70.ckpt' as top 1\n",
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=10, gpus=1, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('DL-01')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2a344cc8269451be292df9fb07df2607f71d7304dd683c993c608f0927a913c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
